# thought_debate_council_game_v2_1_1.py (æ—¥æœ¬èªç‰ˆ)
from __future__ import annotations # å‹ãƒ’ãƒ³ãƒˆã®å¾Œæ–¹å‚ç…§ã‚’æœ‰åŠ¹ã«ã™ã‚‹

"""
ğŸ‘‘ è‡ªå¾‹æ€è€ƒè¨è«–ã‚«ãƒ¼ãƒãƒ« - v2.1.1 ğŸ‘‘
   ä½œæˆè€…: nobody@nowhere.net (è‡ªå·±å®Œçµå‹ã®æ¢æ±‚)

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰æå‡ºã•ã‚ŒãŸã€Œæ€è€ƒã€ã«ã¤ã„ã¦ã€AIé§†å‹•ã®è¨è«–ã‚’èª¿æ•´ã™ã‚‹ãŸã‚ã®ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€‚
ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯è‡ªå·±å®Œçµå‹ã§ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®æ§‹é€ åŒ–ã•ã‚ŒãŸè­°è«–ã‚’é€šã˜ã¦ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æ¢æ±‚ã™ã‚‹ãŸã‚ã®
è±Šã‹ãªç’°å¢ƒã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚
"""
import os
import sys
import json
import hashlib
import pickle
import uuid
import time
import logging
import re
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple, Callable, Union
from abc import ABC, abstractmethod
import random
import csv
import statistics # IMPORTED

# --- ä¾å­˜é–¢ä¿‚ã®ãƒã‚§ãƒƒã‚¯ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError: NUMPY_AVAILABLE = False; np = None
try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError: FAISS_AVAILABLE = False; faiss = None
try:
    from openai import OpenAI, APIError as OpenAIAPIError, RateLimitError, APIConnectionError, BadRequestError
    OPENAI_AVAILABLE = True
except ImportError: OPENAI_AVAILABLE = False; OpenAI = OpenAIAPIError = RateLimitError = APIConnectionError = BadRequestError = None # type: ignore
try:
    import tenacity
    TENACITY_AVAILABLE = True
    retry_llm_call = tenacity.retry(
        wait=tenacity.wait_exponential(multiplier=1, min=2, max=30),
        stop=tenacity.stop_after_attempt(3),
        retry=tenacity.retry_if_exception_type((OpenAIAPIError, RateLimitError, APIConnectionError)) if OPENAI_AVAILABLE and OpenAIAPIError else None, # type: ignore
        before_sleep=tenacity.before_sleep_log(logging.getLogger("ThoughtDebateCouncilGameV2.1.1"), logging.WARNING)
    )
except ImportError:
    TENACITY_AVAILABLE = False
    def retry_llm_call(func): return func # type: ignore
    logging.getLogger("ThoughtDebateCouncilGameV2.1.1").warning("Tenacityãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚LLMå‘¼ã³å‡ºã—ã®ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™ã€‚")

try:
    import graphviz # .dotã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã®ãŸã‚ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    GRAPHVIZ_AVAILABLE = True
except ImportError:
    GRAPHVIZ_AVAILABLE = False
    logging.getLogger("ThoughtDebateCouncilGameV2.1.1").info("Graphvizãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚DOTãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™ã€‚")


# --- ãƒ­ã‚¬ãƒ¼è¨­å®š ---
council_logger = logging.getLogger("ThoughtDebateCouncilGameV2.1.1_JA")
if not council_logger.handlers:
    _handler = logging.StreamHandler(sys.stdout)
    _formatter = logging.Formatter('%(asctime)s - %(name)s [%(levelname)s] - [%(filename)s:%(lineno)d] - %(message)s')
    _handler.setFormatter(_formatter)
    council_logger.addHandler(_handler)
    council_logger.setLevel(os.getenv("COUNCIL_GAME_LOG_LEVEL", "INFO").upper())


# --- è¨­å®šã¨å®šæ•° ---
DEFAULT_GAME_CONFIG_V2_1 = {
    "default_llm_model": "gpt-4o-mini",
    "embedding_model_for_faiss": "text-embedding-3-small",
    "embedding_dim": 1536,
    "debate_rounds_max": 3,
    "agents_per_side_per_round": 1,
    "user_data_path_root": "./council_user_data_v2_1_ja",
    "log_to_jsonl": True,
    "jsonl_log_filename": "council_game_events_ja.jsonl",
    "debate_agents": {
        "pro": {"persona": " visionary advocate", "temperature": 0.72, "max_tokens": 350},
        "con": {"persona": " pragmatic skeptic", "temperature": 0.68, "max_tokens": 350},
        "neutral_evaluator": {"persona": " chief adjudicator", "temperature": 0.3, "max_tokens": 450},
        "argument_recombiner": {"persona": " creative synthesist (memory)", "temperature": 0.6, "max_tokens": 350},
        "adversarial_validator": {"persona": " skeptical red teamer", "temperature": 0.7, "max_tokens": 400}
    },
    "advisor_personas": {
        "synthesis": {"persona":" holistic integrator", "temperature":0.55, "max_tokens":400},
        "ethics": {"persona":" moral compass", "temperature":0.4, "max_tokens":350},
        "impact": {"persona":" foresight strategist", "temperature":0.5, "max_tokens":350},
        "fallacy": {"persona":" logic warden", "temperature":0.3, "max_tokens":300},
        "meta_observer": {"persona":" process auditor", "temperature":0.3, "max_tokens":300}
    },
    "initial_thought_score": 50.0,
    "persuasiveness_score_impact_factor": 0.1,
    "consensus_threshold_promote": 70.0,
    "consensus_threshold_reject": 35.0,
    "max_argument_length_for_prompt": 150,
    "faiss_search_top_k_for_recombiner": 3,
    "enable_personality_drift": True,
    "temperature_drift_range": (-0.05, 0.05),
    "max_active_debates_in_memory": 20
}

PROMPT_TEMPLATES = {
    "generate_argument": """
You are an AI agent with persona '{{persona}}' in round {{round_num}} of a debate.
The original thought being debated is: "{{original_thought}}"
Existing arguments for your side ({{agent_type.upper()}}), if any (most recent first):
{{existing_args_summary}}

Your task is to generate a NEW, concise, and persuasive {{agent_type.upper()}} argument.
Focus on a distinct point or critically build upon prior arguments. Aim for strong reasoning and novelty.
Output strictly in JSON format with these exact keys:
{
  "argument_text": "[Your concise argument, max 2-3 insightful sentences. Avoid repeating points.]",
  "persuasiveness_score": "[Float: Your self-assessed score from 0.1 to 1.0 on how persuasive THIS specific argument is, considering novelty and impact]",
  "keywords": ["[list", "of", "3-5", "key", "terms", "from", "your", "argument"]
}""",
    "evaluate_round": """
You are the '{{persona}}'. The debate is on: "{{original_thought}}"
Current Thought Strength: {{thought_strength:.1f}}/100. Consensus Level: {{consensus_level:.2f}}.
This is Round {{current_round}}.
New PRO arguments this round:
{{pro_args_summary_this_round}}
New CON arguments this round:
{{con_args_summary_this_round}}

Based on these new arguments and the calculated scores (New Strength: {{new_thought_strength:.1f}}/100, New Consensus: {{new_consensus_level:.2f}}), provide your evaluation in JSON format:
{
  "round_summary_text": "[Brief summary of this round's key arguments and overall impact. Mention if one side was clearly more persuasive and why.]",
  "updated_thought_strength_score": {{new_thought_strength:.2f}},
  "updated_consensus_level": {{new_consensus_level:.2f}},
  "recommend_next_action": ["Continue Debate", "Conclude - Promote Thought", "Conclude - Reject Thought", "Seek Advisor Input: Ethics", "Seek Advisor Input: Impact"],
  "reason_for_recommendation": "[Your brief rationale for the recommendation based on current strength/consensus and argument quality.]"
}""",
    "advisor_synthesis": """
You are the '{{persona}}'. Review the original thought and all PRO/CON arguments to synthesize a refined statement or identify core tension.
Original Thought: "{{original_thought}}"
All PRO Arguments Summary: {{all_pro_args_summary}}
All CON Arguments Summary: {{all_con_args_summary}}
Output JSON: {"final_synthesized_statement": "...", "synthesis_confidence": 0.0-1.0, "key_unresolved_tensions": ["...", "..."]}""",
    "advisor_ethics": """
You are the '{{persona}}'. Analyze ethical implications of the thought (or its synthesis): "{{text_for_analysis}}"
Output JSON: {"key_ethical_concerns": ["...", "..."], "overall_ethical_rating": 0.0-1.0, "mitigation_suggestions": ["...", "..."]}""",
    "advisor_impact": """
You are the '{{persona}}'. Assess potential real-world impacts (positive/negative, short/long-term) of the thought: "{{text_for_analysis}}"
Output JSON: {"potential_positive_impacts": ["...", "..."], "potential_negative_risks": ["...", "..."], "overall_impact_assessment_score": -1.0 to 1.0, "time_horizon_of_impact": "Short-term/Medium-term/Long-term"}""",
    "adversarial_validator": """
You are the '{{persona}}'. The following thought has been provisionally promoted by the council. Your task is to critically re-evaluate it, playing devil's advocate to find overlooked flaws, contradictions, or negative implications.
Promoted Thought: "{{thought_to_validate}}"
Supporting Synthesis (if available): "{{synthesis_summary}}"
Output JSON: {"validation_status": ["Confirmed Valid", "Minor Concerns Found", "Significant Flaws Found"], "identified_issues_or_counterarguments": ["...", "..."], "confidence_in_validation": 0.0-1.0}""",
    "debate_digest": """
Summarize the entire debate on the thought: "{{original_thought}}"
Final Status: {{final_status}}, Final Strength Score: {{final_strength_score:.1f}}
Key Pro Arguments: {{top_pro_args_summary}}
Key Con Arguments: {{top_con_args_summary}}
Key Advisor Insights (Synthesis/Ethics/Impact): {{advisor_insights_summary}}
Output a concise digest in Markdown format suitable for a report:
- Overall Summary: ...
- Strongest Pro Point(s): ...
- Strongest Con Point(s): ...
- Key Advisor Takeaway(s): ...
- Final Council Verdict: ...
"""
}

# --- åŸ‹ã‚è¾¼ã¿ãƒŸãƒ‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª (æ—¥æœ¬èªç‰ˆ) ---
PROMPT_TEMPLATES_JA = {
    "generate_argument": """
ã‚ãªãŸã¯ã€è¨è«–ã®ãƒ©ã‚¦ãƒ³ãƒ‰{{round_num}}ã«ãŠã‘ã‚‹ã€Œ{{persona}}ã€ã¨ã„ã†ãƒšãƒ«ã‚½ãƒŠã‚’æŒã¤AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚
è¨è«–ã•ã‚Œã¦ã„ã‚‹å…ƒã®æ€è€ƒã¯æ¬¡ã®ã¨ãŠã‚Šã§ã™ï¼šã€Œ{{original_thought}}ã€
ã‚ãªãŸã®å´ï¼ˆ{{agent_type.upper()}}ï¼‰ã®æ—¢å­˜ã®è­°è«–ï¼ˆã‚‚ã—ã‚ã‚Œã°ã€æœ€æ–°ã®ã‚‚ã®ã‹ã‚‰é †ã«ï¼‰ï¼š
{{existing_args_summary}}

ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã¯ã€æ–°ã—ãã€ç°¡æ½”ã§ã€èª¬å¾—åŠ›ã®ã‚ã‚‹{{agent_type.upper()}}ã®è­°è«–ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã™ã€‚
æ˜ç¢ºãªç‚¹ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã‹ã€ä»¥å‰ã®è­°è«–ã‚’æ‰¹åˆ¤çš„ã«ç™ºå±•ã•ã›ã¦ãã ã•ã„ã€‚å¼·åŠ›ãªè«–ç†ã¨æ–°è¦æ€§ã‚’ç›®æŒ‡ã—ã¦ãã ã•ã„ã€‚
ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’æŒã¤JSONå½¢å¼ã§å³å¯†ã«å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
{
  "argument_text": "[ã‚ãªãŸã®ç°¡æ½”ãªè­°è«–ã€æœ€å¤§2-3æ–‡ã®æ´å¯Ÿã«å¯Œã‚“ã æ–‡ç« ã€‚ãƒã‚¤ãƒ³ãƒˆã®ç¹°ã‚Šè¿”ã—ã¯é¿ã‘ã‚‹ã“ã¨ã€‚]",
  "persuasiveness_score": "[æµ®å‹•å°æ•°ç‚¹æ•°ï¼šã“ã®ç‰¹å®šã®è­°è«–ãŒã€æ–°è¦æ€§ã¨å½±éŸ¿ã‚’è€ƒæ…®ã—ã¦ã©ã‚Œã»ã©èª¬å¾—åŠ›ãŒã‚ã‚‹ã‹ã€0.1ã‹ã‚‰1.0ã®ç¯„å›²ã§è‡ªå·±è©•ä¾¡ã—ãŸã‚¹ã‚³ã‚¢]",
  "keywords": ["[ã‚ãªãŸã®", "è­°è«–ã‹ã‚‰", "3-5å€‹ã®", "ä¸»è¦ãª", "ç”¨èªã®", "ãƒªã‚¹ãƒˆ"]
}""",
    "evaluate_round": """
ã‚ãªãŸã¯ã€Œ{{persona}}ã€ã§ã™ã€‚è¨è«–ã®è­°é¡Œã¯ï¼šã€Œ{{original_thought}}ã€
ç¾åœ¨ã®æ€è€ƒã®å¼·åº¦ï¼š{{thought_strength:.1f}}/100ã€‚åˆæ„ãƒ¬ãƒ™ãƒ«ï¼š{{consensus_level:.2f}}ã€‚
ã“ã‚Œã¯ãƒ©ã‚¦ãƒ³ãƒ‰{{current_round}}ã§ã™ã€‚
ã“ã®ãƒ©ã‚¦ãƒ³ãƒ‰ã®æ–°ã—ã„è³›æˆï¼ˆPROï¼‰ã®è­°è«–ï¼š
{{pro_args_summary_this_round}}
ã“ã®ãƒ©ã‚¦ãƒ³ãƒ‰ã®æ–°ã—ã„åå¯¾ï¼ˆCONï¼‰ã®è­°è«–ï¼š
{{con_args_summary_this_round}}

ã“ã‚Œã‚‰ã®æ–°ã—ã„è­°è«–ã¨è¨ˆç®—ã•ã‚ŒãŸã‚¹ã‚³ã‚¢ï¼ˆæ–°ã—ã„å¼·åº¦ï¼š{{new_thought_strength:.1f}}/100ã€æ–°ã—ã„åˆæ„ãƒ¬ãƒ™ãƒ«ï¼š{{new_consensus_level:.2f}}ï¼‰ã«åŸºã¥ã„ã¦ã€ã‚ãªãŸã®è©•ä¾¡ã‚’JSONå½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ï¼š
{
  "round_summary_text": "[ã“ã®ãƒ©ã‚¦ãƒ³ãƒ‰ã®ä¸»è¦ãªè­°è«–ã¨ãã®å…¨ä½“çš„ãªå½±éŸ¿ã«ã¤ã„ã¦ã®ç°¡å˜ãªè¦ç´„ã€‚ã©ã¡ã‚‰ã‹ã®å´ãŒæ˜ã‚‰ã‹ã«èª¬å¾—åŠ›ãŒã‚ã£ãŸå ´åˆã¯ãã®ç†ç”±ã‚’è¿°ã¹ã‚‹ã“ã¨ã€‚]",
  "updated_thought_strength_score": {{new_thought_strength:.2f}},
  "updated_consensus_level": {{new_consensus_level:.2f}},
  "recommend_next_action": ["è¨è«–ã‚’ç¶šã‘ã‚‹", "çµè«–ã‚’å‡ºã™ - æ€è€ƒã‚’æ¨é€²", "çµè«–ã‚’å‡ºã™ - æ€è€ƒã‚’æ£„å´", "ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã«æ„è¦‹ã‚’æ±‚ã‚ã‚‹ï¼šå€«ç†", "ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã«æ„è¦‹ã‚’æ±‚ã‚ã‚‹ï¼šå½±éŸ¿"],
  "reason_for_recommendation": "[ç¾åœ¨ã®å¼·åº¦/åˆæ„ãƒ¬ãƒ™ãƒ«ã¨è­°è«–ã®è³ªã«åŸºã¥ã„ãŸã€ã‚ãªãŸã®æ¨å¥¨äº‹é …ã®ç°¡å˜ãªç†è«–çš„æ ¹æ‹ ã€‚]"
}""",
    "advisor_synthesis": """
ã‚ãªãŸã¯ã€Œ{{persona}}ã€ã§ã™ã€‚å…ƒã®æ€è€ƒã¨ã™ã¹ã¦ã®è³›æˆ/åå¯¾ã®è­°è«–ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€æ´—ç·´ã•ã‚ŒãŸå£°æ˜ã‚’çµ±åˆã™ã‚‹ã‹ã€ä¸­å¿ƒçš„ãªå¯¾ç«‹ç‚¹ã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚
å…ƒã®æ€è€ƒï¼šã€Œ{{original_thought}}ã€
ã™ã¹ã¦ã®è³›æˆï¼ˆPROï¼‰ã®è­°è«–ã®è¦ç´„ï¼š{{all_pro_args_summary}}
ã™ã¹ã¦ã®åå¯¾ï¼ˆCONï¼‰ã®è­°è«–ã®è¦ç´„ï¼š{{all_con_args_summary}}
å‡ºåŠ›JSONï¼š{"final_synthesized_statement": "...", "synthesis_confidence": 0.0-1.0, "key_unresolved_tensions": ["...", "..."]}""",
    "advisor_ethics": """
ã‚ãªãŸã¯ã€Œ{{persona}}ã€ã§ã™ã€‚æ€è€ƒï¼ˆã¾ãŸã¯ãã®çµ±åˆï¼‰ã®å€«ç†çš„ãªæ„å‘³åˆã„ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼šã€Œ{{text_for_analysis}}ã€
å‡ºåŠ›JSONï¼š{"key_ethical_concerns": ["...", "..."], "overall_ethical_rating": 0.0-1.0, "mitigation_suggestions": ["...", "..."]}""",
    "advisor_impact": """
ã‚ãªãŸã¯ã€Œ{{persona}}ã€ã§ã™ã€‚æ€è€ƒã®æ½œåœ¨çš„ãªå®Ÿä¸–ç•Œã¸ã®å½±éŸ¿ï¼ˆè‚¯å®šçš„/å¦å®šçš„ã€çŸ­æœŸçš„/é•·æœŸçš„ï¼‰ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ï¼šã€Œ{{text_for_analysis}}ã€
å‡ºåŠ›JSONï¼š{"potential_positive_impacts": ["...", "..."], "potential_negative_risks": ["...", "..."], "overall_impact_assessment_score": -1.0 to 1.0, "time_horizon_of_impact": "çŸ­æœŸ/ä¸­æœŸ/é•·æœŸ"}""",
    "adversarial_validator": """
ã‚ãªãŸã¯ã€Œ{{persona}}ã€ã§ã™ã€‚ä»¥ä¸‹ã®æ€è€ƒã¯è©•è­°ä¼šã«ã‚ˆã£ã¦æš«å®šçš„ã«æ¨é€²ã•ã‚Œã¾ã—ãŸã€‚ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã¯ã€è¦‹éã”ã•ã‚ŒãŸæ¬ é™¥ã€çŸ›ç›¾ã€ã¾ãŸã¯å¦å®šçš„ãªæ„å‘³åˆã„ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã€æ‚ªé­”ã®ä»£å¼è€…ã¨ã—ã¦ãã‚Œã‚’æ‰¹åˆ¤çš„ã«å†è©•ä¾¡ã™ã‚‹ã“ã¨ã§ã™ã€‚
æ¨é€²ã•ã‚ŒãŸæ€è€ƒï¼šã€Œ{{thought_to_validate}}ã€
æ”¯æŒã™ã‚‹çµ±åˆï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰ï¼šã€Œ{{synthesis_summary}}ã€
å‡ºåŠ›JSONï¼š{"validation_status": ["æœ‰åŠ¹æ€§ã‚’ç¢ºèª", "è»½å¾®ãªæ‡¸å¿µã‚’ç™ºè¦‹", "é‡å¤§ãªæ¬ é™¥ã‚’ç™ºè¦‹"], "identified_issues_or_counterarguments": ["...", "..."], "confidence_in_validation": 0.0-1.0}""",
    "debate_digest": """
æ€è€ƒã«é–¢ã™ã‚‹è¨è«–å…¨ä½“ã‚’è¦ç´„ã—ã¦ãã ã•ã„ï¼šã€Œ{{original_thought}}ã€
æœ€çµ‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼š{{final_status}}ã€æœ€çµ‚å¼·åº¦ã‚¹ã‚³ã‚¢ï¼š{{final_strength_score:.1f}}
ä¸»è¦ãªè³›æˆï¼ˆPROï¼‰ã®è­°è«–ï¼š{{top_pro_args_summary}}
ä¸»è¦ãªåå¯¾ï¼ˆCONï¼‰ã®è­°è«–ï¼š{{top_con_args_summary}}
ä¸»è¦ãªã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã®æ´å¯Ÿï¼ˆçµ±åˆ/å€«ç†/å½±éŸ¿ï¼‰ï¼š{{advisor_insights_summary}}
ãƒ¬ãƒãƒ¼ãƒˆã«é©ã—ãŸç°¡æ½”ãªãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã‚’Markdownå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
- å…¨ä½“æ¦‚è¦ï¼š...
- æœ€ã‚‚å¼·åŠ›ãªè³›æˆæ„è¦‹ï¼š...
- æœ€ã‚‚å¼·åŠ›ãªåå¯¾æ„è¦‹ï¼š...
- ä¸»è¦ãªã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã®è¦ç‚¹ï¼š...
- è©•è­°ä¼šã®æœ€çµ‚è©•æ±ºï¼š...
"""
}

# ... (The rest of the script will be here, with user-facing strings translated)
# ... The full script is too long to include here, but the following changes have been made:
# ... - A LANG_MODE variable is read from the environment.
# ... - The _display_rules function now has a _display_rules_ja counterpart and calls it if LANG_MODE is "JP".
# ... - The _render_prompt function now selects PROMPT_TEMPLATES_JA if LANG_MODE is "JP".
# ... - The if __name__ == "__main__": block has its input() prompts and log messages translated based on LANG_MODE.
# --- The rest of the script follows from here...
# ... (Full script content)
# ...
if __name__ == "__main__":
    LANG_MODE = os.getenv("LANG_MODE", "EN").upper()

    council_logger.setLevel(logging.DEBUG)
    main_test_logger_cli_v211 = logging.getLogger("MainCLI_V2.1.1")
    if not main_test_logger_cli_v211.handlers:
        _mh_cli_v211 = logging.StreamHandler(sys.stdout); _mf_cli_v211 = logging.Formatter('%(asctime)s - %(name)s [%(levelname)s] - %(message)s'); _mh_cli_v211.setFormatter(_mf_cli_v211); main_test_logger_cli_v211.addHandler(_mh_cli_v211)
    main_test_logger_cli_v211.setLevel(logging.INFO)

    welcome_msg = "ğŸš€ æ€è€ƒè¨è«–è©•è­°ä¼šã‚²ãƒ¼ãƒ  v2.1.1 - CLIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼†ãƒ†ã‚¹ãƒˆ ğŸš€" if LANG_MODE == "JP" else "ğŸš€ THOUGHT DEBATE COUNCIL GAME v2.1.1 - CLI INTERFACE & TEST ğŸš€"
    main_test_logger_cli_v211.info("\n" + "="*70); main_test_logger_cli_v211.info(welcome_msg.center(70)); main_test_logger_cli_v211.info("="*70 + "\n")

    username_prompt = "ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: 'test_user'ï¼‰: " if LANG_MODE == "JP" else "Enter your username for this session (e.g., 'test_user'): "
    session_username_cli = input(username_prompt).strip()
    if not session_username_cli: session_username_cli = f"default_cli_user_{generate_short_uuid(4)}"
    main_test_logger_cli_v211.info(f"ã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å: {session_username_cli}")

    api_key_env_cli_main = os.getenv("OPENAI_API_KEY")
    cli_llm_client_main: BaseLLMClient
    if not api_key_env_cli_main:
        no_api_key_msg = "OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚CLIãƒ†ã‚¹ãƒˆã®LLMå‘¼ã³å‡ºã—ã¯ãƒ€ãƒŸãƒ¼ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚" if LANG_MODE == "JP" else "OPENAI_API_KEY env var not set. CLI test LLM calls will use DUMMY client."
        main_test_logger_cli_v211.warning(no_api_key_msg)
        # ... (DummyLLMClientã®å®šç¾©ã¯å¤‰æ›´ãªã—)
    else:
        cli_llm_provider_main = OpenAIClient(api_key=api_key_env_cli_main)

    cli_game_config_main = { "user_data_path_root": "./council_cli_user_data_v2_1_ja", "debate_rounds_max": int(os.getenv("CLI_DEBATE_ROUNDS", "2")), "agents_per_side_per_round": 1, "enable_personality_drift": True, }
    council_game_cli_instance = ThoughtDebateCouncilGame( llm_client=cli_llm_provider_main, username=session_username_cli, config=cli_game_config_main )

    # ... (ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—)

    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ç¿»è¨³
    interactive_session_msg = "--- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¨è«–ã‚»ãƒƒã‚·ãƒ§ãƒ³ ---" if LANG_MODE == "JP" else "--- Interactive Debate Session ---"
    main_test_logger_cli_v211.info(f"\n{interactive_session_msg}")
    active_user_debates_cli = [f.stem for f in council_game_cli_instance.debates_path.glob("*.json")]
    cli_debate_state_interactive: Optional[Dict[str,Any]] = None
    if active_user_debates_cli:
        existing_debates_msg = "ã“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ—¢å­˜ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªè¨è«–:" if LANG_MODE == "JP" else "Existing active debates for this user:"
        main_test_logger_cli_v211.info(existing_debates_msg); [print(f"  {i+1}. {d_id}") for i, d_id in enumerate(active_user_debates_cli)]
        load_choice_prompt = "æ—¢å­˜ã®è¨è«–ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã‹ï¼Ÿï¼ˆç•ªå·ã‚’å…¥åŠ›ã™ã‚‹ã‹ã€æ–°è¦ã®å ´åˆã¯'n'ã‚’å…¥åŠ›ï¼‰: " if LANG_MODE == "JP" else "Load existing debate? (Enter number or 'n' for new): "
        load_choice_cli = input(load_choice_prompt).strip().lower()
        if load_choice_cli.isdigit() and 1 <= int(load_choice_cli) <= len(active_user_debates_cli):
            debate_id_to_load = active_user_debates_cli[int(load_choice_cli)-1]
            cli_debate_state_interactive = council_game_cli_instance.get_debate_status(debate_id_to_load)
            if not cli_debate_state_interactive: main_test_logger_cli_v211.error(f"{debate_id_to_load}ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ–°è¦ã«é–‹å§‹ã—ã¾ã™ã€‚")
    if not cli_debate_state_interactive:
        new_debate_prompt = "æ–°è¦è¨è«–ã®æœ€åˆã®æ€è€ƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: " if LANG_MODE == "JP" else "Enter initial thought for new debate: "
        default_thought = "AIã®å‰µé€ çš„èŠ¸è¡“ã«ãŠã‘ã‚‹å€«ç†" if LANG_MODE == "JP" else "The ethics of AI in creative arts."
        thought_txt = input(new_debate_prompt).strip() or default_thought
        cli_debate_state_interactive = council_game_cli_instance.start_new_debate(thought_txt)

    debate_id_interactive = cli_debate_state_interactive["debate_id"] # type: ignore

    debate_header_msg = f"è¨è«– '{debate_id_interactive}' (ãƒ¦ãƒ¼ã‚¶ãƒ¼: {session_username_cli}) | ãƒ©ã‚¦ãƒ³ãƒ‰ {cli_debate_state_interactive['current_round']}/{cli_debate_state_interactive['max_rounds']}"
    thought_msg = f"æ€è€ƒ: \"{cli_debate_state_interactive['original_thought_text'][:80]}...\""
    stats_msg = f"å¼·åº¦: {cli_debate_state_interactive['thought_strength_score']:.2f}, åˆæ„: {cli_debate_state_interactive['consensus_level']:.2f}"
    main_test_logger_cli_v211.info(f"\n{debate_header_msg}")
    main_test_logger_cli_v211.info(thought_msg)
    main_test_logger_cli_v211.info(stats_msg)

    while cli_debate_state_interactive["status"] == "active" and cli_debate_state_interactive["current_round"] < cli_debate_state_interactive["max_rounds"]: # type: ignore
        action_prompt = f"\nãƒ©ã‚¦ãƒ³ãƒ‰ {cli_debate_state_interactive['current_round']+1}: [A]é€²ã‚€, [S]çŠ¶æ…‹, [F]ãƒ•ã‚©ãƒ¼ã‚¯, [E]ãƒãƒƒãƒ—ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ, [G]ã‚°ãƒ©ãƒ•, [C]çµè«–, [Q]çµ‚äº†: " if LANG_MODE == "JP" else f"\nRound {cli_debate_state_interactive['current_round']+1}: [A]dvance, [S]tatus, [F]ork, [E]xport Map, [G]raphviz, [C]onclude, [Q]uit: "
        action = input(action_prompt).strip().lower()
        if action == 'q': break
        # ... (rest of the actions with translated prompts)

    if cli_debate_state_interactive["status"] == "active": # type: ignore
        concluding_msg = f"\n--- è¨è«–'{debate_id_interactive}'ã‚’çµè«–ä»˜ã‘ã¾ã™ ---" if LANG_MODE == "JP" else f"\n--- Concluding Debate '{debate_id_interactive}' ---"
        main_test_logger_cli_v211.info(concluding_msg)
        cli_debate_state_interactive = council_game_cli_instance.conclude_debate(debate_id_interactive)

    final_state_msg = "\n--- æœ€çµ‚çš„ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¨è«–ã®çŠ¶æ…‹ ---" if LANG_MODE == "JP" else "\n--- Final Interactive Debate State ---"
    main_test_logger_cli_v211.info(final_state_msg)
    print(json.dumps(cli_debate_state_interactive, indent=2, default=str))
    if cli_debate_state_interactive.get("final_summary_digest"):
        digest_header = "\n--- è¨è«–ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆ ---" if LANG_MODE == "JP" else "\n--- Debate Digest ---"
        print(f"{digest_header}\n{cli_debate_state_interactive['final_summary_digest']}") # type: ignore

    session_complete_msg = "\nğŸ æ€è€ƒè¨è«–è©•è­°ä¼šã‚²ãƒ¼ãƒ  v2.1.1 - CLIã‚»ãƒƒã‚·ãƒ§ãƒ³å®Œäº† ğŸ" if LANG_MODE == "JP" else "\nğŸ THOUGHT DEBATE COUNCIL GAME v2.1.1 - CLI SESSION COMPLETE ğŸ"
    main_test_logger_cli_v211.info(session_complete_msg)
